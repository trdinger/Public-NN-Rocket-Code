{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essential imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the *headers* for the API request call with credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "my_id = os.getenv('IBM_CLIENT_ID')\n",
    "my_secret = os.getenv('IBM_CLIENT_SECRET')\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"X-IBM-Client-Id\": my_id,\n",
    "    \"X-IBM-Client-Secret\" : my_secret\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set urls and file variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://api.ibm.com/\"\n",
    "tsc_service = \"timeseriesclass/run/timeseriesclassification/\"\n",
    "health_check = tsc_service + \"health_check\"\n",
    "nnrocket_svc = tsc_service + \"nnrocket\"\n",
    "status_check_svc = tsc_service + \"status/\"\n",
    "\n",
    "data_file = \"sample01.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary *health check* to make sure your credentials are OK and you can access the service!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_health_check_url = base_url + health_check\n",
    "print(full_health_check_url)\n",
    "response = requests.get(full_health_check_url, headers=headers)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare *parameters* and *files* inputs for the HTTP request for accessing the NN Rocket service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = (\n",
    "    ('time column', 'Time'),\n",
    "    ('time string format', '%Y-%m-%d %H:%M:%S'),\n",
    "    ('target columns', '[\"Value1\",\"Value2\",\"Value3\",\"Value4\",\"Value5\"]'),\n",
    "    ('categorical columns', '[\"Category1\",\"Category2\",\"Category3\"]'),\n",
    "    ('label column', 'Label'),\n",
    "    ('snapshot column', 'Snapshot'),\n",
    "    ('train test split', '0.5'),\n",
    "    ('result type', 'accuracy'),\n",
    ")\n",
    "files = {'data file': open(data_file, \"rb\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your data file in CSV format & various validation checks, prior to making the HTTP request\n",
    "> ## The *validator* function below makes several basic sanity checks to help you avoid surprises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params_dict = dict(params)\n",
    "time_column = params_dict['time column']\n",
    "time_format = params_dict['time string format']\n",
    "target_columns = json.loads(params_dict['target columns'])\n",
    "label_column =  params_dict['label column']\n",
    "snapshot_column = params_dict['snapshot column']\n",
    "\n",
    "def validator(data_file, time_column, time_format, target_columns, label_column, snapshot_column):\n",
    "\n",
    "    try:\n",
    "        userdf = pd.read_csv(data_file)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(\"Submitted csv file not found.\")\n",
    "    except EmptyDataError:\n",
    "        raise EmptyDataError(\"There is no data in the submitted csv\")\n",
    "    except ParserError:\n",
    "        raise ParserError(\"There is an issue parsing the submitted csv\")\n",
    "\n",
    "    # check column headings\n",
    "    column_names = userdf.columns\n",
    "    if time_column not in column_names:\n",
    "        raise ValueError(time_column+'  not found in submitted csv file')\n",
    "    if label_column not in column_names:\n",
    "        raise ValueError(label_column+'  not found in submitted csv file')\n",
    "    if snapshot_column not in column_names:\n",
    "        raise ValueError(snapshot_column+'  not found in submitted csv file')\n",
    "    # check target columns exist and is numeric \n",
    "    for t in target_columns:\n",
    "        if t not in column_names:\n",
    "            raise ValueError(t+'  not found in submitted csv file')\n",
    "        else:\n",
    "            if not userdf[t].apply(np.isreal).all(axis=None):\n",
    "                raise ValueError('Non numeric values found in column ',t)\n",
    "\n",
    "    # check time formatting\n",
    "    try:\n",
    "        userdf[time_column] = pd.to_datetime(userdf[time_column],format=time_format)\n",
    "    except ValueError as e:\n",
    "        raise ValueError('Specified time column not recognized'+e)\n",
    "\n",
    "    # check distinct timestamps\n",
    "    uniquetscount = userdf[[snapshot_column, time_column]].groupby([snapshot_column]).nunique()[time_column].tolist() \n",
    "    numtscount = userdf[[snapshot_column, time_column]].groupby([snapshot_column]).size().tolist()\n",
    "    if uniquetscount != numtscount:\n",
    "        raise ValueError('Duplicate timestamps detected in the csv')\n",
    "\n",
    "    # check label column for single cases\n",
    "    groupbylabel = userdf[[snapshot_column, label_column]].groupby(snapshot_column).mean()\n",
    "    labelid = groupbylabel[label_column]\n",
    "    if labelid.value_counts(ascending=True).tolist()[0] < 5:\n",
    "        raise ValueError('One or more labels have less than five snapshot instances and thus insufficient training sample')\n",
    "\n",
    "    return userdf\n",
    "\n",
    "user_df = validator(data_file, time_column, time_format, target_columns, label_column, snapshot_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect data prior to sending it across"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the HTTP request using the *requests* module\n",
    "> ## It returns a *task_id*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "full_svc_url = base_url+nnrocket_svc\n",
    "print(full_svc_url)\n",
    "response = requests.post(full_svc_url, headers=headers, params=params, files=files)\n",
    "task_id = response.text\n",
    "task_id=task_id.replace('\"\"','').rstrip()\n",
    "print(task_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a status check call against the above returned *task_id* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_status_check_url = base_url+status_check_svc + task_id.replace('\"', '')\n",
    "print(full_status_check_url)\n",
    "response = requests.get(full_status_check_url, headers=headers)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Again! Using the same *task_id* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = requests.get(full_status_check_url, headers=headers)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
