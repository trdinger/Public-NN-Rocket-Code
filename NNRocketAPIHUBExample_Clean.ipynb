{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Essential imports "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import json\n",
    "import numpy as np\n",
    "import time\n",
    "import os\n",
    "from dotenv import load_dotenv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare the *headers* for the API request call with credentials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "load_dotenv()\n",
    "\n",
    "my_id = os.getenv('IBM_CLIENT_ID')\n",
    "my_secret = os.getenv('IBM_CLIENT_SECRET')\n",
    "\n",
    "headers = {\n",
    "    \"accept\": \"application/json\",\n",
    "    \"X-IBM-Client-Id\": my_id,\n",
    "    \"X-IBM-Client-Secret\" : my_secret\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Set urls and file variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_url = \"https://api.ibm.com/\"\n",
    "tsc_service = \"timeseriesclass/run/timeseriesclassification/\"\n",
    "health_check = tsc_service + \"health_check\"\n",
    "nnrocket_svc = tsc_service + \"nnrocket\"\n",
    "status_check_svc = tsc_service + \"status/\"\n",
    "\n",
    "data_file = \"sample01.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preliminary *health check* to make sure your credentials are OK and you can access the service!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "full_health_check_url = base_url + health_check\n",
    "print(full_health_check_url)\n",
    "response = requests.get(full_health_check_url, headers=headers)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prepare *parameters* and *files* inputs for the HTTP request for accessing the NN Rocket service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = (\n",
    "    ('time column', 'Time'),\n",
    "    ('time string format', '%Y-%m-%d %H:%M:%S'),\n",
    "    ('target columns', '[\"Value1\",\"Value2\",\"Value3\",\"Value4\",\"Value5\"]'),\n",
    "    ('categorical columns', '[\"Category1\",\"Category2\",\"Category3\"]'),\n",
    "    ('label column', 'Label'),\n",
    "    ('snapshot column', 'Snapshot'),\n",
    "    ('train test split', '0.5'),\n",
    "    ('result type', 'accuracy'), # accuracy, precision-labels, f1-score\n",
    ")\n",
    "files = {'data file': open(data_file, \"rb\")}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Your data file in CSV format & various validation checks, prior to making the HTTP request\n",
    "> ## The *validator* function below makes several basic sanity checks to help you avoid surprises"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "params_dict = dict(params)\n",
    "time_column = params_dict['time column']\n",
    "time_format = params_dict['time string format']\n",
    "target_columns = json.loads(params_dict['target columns'])\n",
    "label_column =  params_dict['label column']\n",
    "snapshot_column = params_dict['snapshot column']\n",
    "\n",
    "def validator(data_file, time_column, time_format, target_columns, label_column, snapshot_column):\n",
    "\n",
    "    try:\n",
    "        userdf = pd.read_csv(data_file)\n",
    "    except FileNotFoundError:\n",
    "        raise FileNotFoundError(\"Submitted csv file not found.\")\n",
    "    except EmptyDataError:\n",
    "        raise EmptyDataError(\"There is no data in the submitted csv\")\n",
    "    except ParserError:\n",
    "        raise ParserError(\"There is an issue parsing the submitted csv\")\n",
    "\n",
    "    # check column headings\n",
    "    column_names = userdf.columns\n",
    "    if time_column not in column_names:\n",
    "        raise ValueError(time_column+'  not found in submitted csv file')\n",
    "    if label_column not in column_names:\n",
    "        raise ValueError(label_column+'  not found in submitted csv file')\n",
    "    if snapshot_column not in column_names:\n",
    "        raise ValueError(snapshot_column+'  not found in submitted csv file')\n",
    "    # check target columns exist and is numeric \n",
    "    for t in target_columns:\n",
    "        if t not in column_names:\n",
    "            raise ValueError(t+'  not found in submitted csv file')\n",
    "        else:\n",
    "            if not userdf[t].apply(np.isreal).all(axis=None):\n",
    "                raise ValueError('Non numeric values found in column ',t)\n",
    "\n",
    "    # check time formatting\n",
    "    try:\n",
    "        userdf[time_column] = pd.to_datetime(userdf[time_column],format=time_format)\n",
    "    except ValueError as e:\n",
    "        raise ValueError('Specified time column not recognized'+e)\n",
    "\n",
    "    # check distinct timestamps\n",
    "    uniquetscount = userdf[[snapshot_column, time_column]].groupby([snapshot_column]).nunique()[time_column].tolist() \n",
    "    numtscount = userdf[[snapshot_column, time_column]].groupby([snapshot_column]).size().tolist()\n",
    "    if uniquetscount != numtscount:\n",
    "        raise ValueError('Duplicate timestamps detected in the csv')\n",
    "\n",
    "    # check label column for single cases\n",
    "    groupbylabel = userdf[[snapshot_column, label_column]].groupby(snapshot_column).mean()\n",
    "    labelid = groupbylabel[label_column]\n",
    "    if labelid.value_counts(ascending=True).tolist()[0] < 5:\n",
    "        raise ValueError('One or more labels have less than five snapshot instances and thus insufficient training sample')\n",
    "\n",
    "    return userdf\n",
    "\n",
    "user_df = validator(data_file, time_column, time_format, target_columns, label_column, snapshot_column)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Inspect data prior to sending it across"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Snapshot</th>\n",
       "      <th>Label</th>\n",
       "      <th>Time</th>\n",
       "      <th>Value1</th>\n",
       "      <th>Value2</th>\n",
       "      <th>Value3</th>\n",
       "      <th>Value4</th>\n",
       "      <th>Value5</th>\n",
       "      <th>Category1</th>\n",
       "      <th>Category2</th>\n",
       "      <th>Category3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-21 19:00:00</td>\n",
       "      <td>1</td>\n",
       "      <td>8000</td>\n",
       "      <td>0.841471</td>\n",
       "      <td>1000</td>\n",
       "      <td>0.607572</td>\n",
       "      <td>A</td>\n",
       "      <td>A</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-21 20:00:00</td>\n",
       "      <td>2</td>\n",
       "      <td>7999</td>\n",
       "      <td>0.909297</td>\n",
       "      <td>1001</td>\n",
       "      <td>0.965146</td>\n",
       "      <td>A</td>\n",
       "      <td>B</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-21 21:00:00</td>\n",
       "      <td>3</td>\n",
       "      <td>7998</td>\n",
       "      <td>0.141120</td>\n",
       "      <td>1002</td>\n",
       "      <td>0.925591</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-21 22:00:00</td>\n",
       "      <td>4</td>\n",
       "      <td>7997</td>\n",
       "      <td>-0.756802</td>\n",
       "      <td>1003</td>\n",
       "      <td>0.505182</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2025-09-21 23:00:00</td>\n",
       "      <td>5</td>\n",
       "      <td>7996</td>\n",
       "      <td>-0.958924</td>\n",
       "      <td>1004</td>\n",
       "      <td>-0.123094</td>\n",
       "      <td>A</td>\n",
       "      <td>C</td>\n",
       "      <td>E</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Snapshot  Label                Time  Value1  Value2    Value3  Value4  \\\n",
       "0         0      0 2025-09-21 19:00:00       1    8000  0.841471    1000   \n",
       "1         0      0 2025-09-21 20:00:00       2    7999  0.909297    1001   \n",
       "2         0      0 2025-09-21 21:00:00       3    7998  0.141120    1002   \n",
       "3         0      0 2025-09-21 22:00:00       4    7997 -0.756802    1003   \n",
       "4         0      0 2025-09-21 23:00:00       5    7996 -0.958924    1004   \n",
       "\n",
       "     Value5 Category1 Category2 Category3  \n",
       "0  0.607572         A         A         E  \n",
       "1  0.965146         A         B         E  \n",
       "2  0.925591         A         C         E  \n",
       "3  0.505182         A         C         E  \n",
       "4 -0.123094         A         C         E  "
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make the HTTP request using the *requests* module\n",
    "> ## It returns a *task_id*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.ibm.com/timeseriesclass/run/timeseriesclassification/nnrocket\n",
      "\"0dc8fab5cd62403fa3ae62b73b93b8c5\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "full_svc_url = base_url+nnrocket_svc\n",
    "print(full_svc_url)\n",
    "response = requests.post(full_svc_url, headers=headers, params=params, files=files)\n",
    "task_id = response.text\n",
    "task_id=task_id.replace('\"\"','').rstrip()\n",
    "print(task_id)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Make a status check call against the above returned *task_id* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "https://api.ibm.com/timeseriesclass/run/timeseriesclassification/status/0dc8fab5cd62403fa3ae62b73b93b8c5\n",
      "\"task is running..\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "full_status_check_url = base_url+status_check_svc + task_id.replace('\"', '')\n",
    "print(full_status_check_url)\n",
    "response = requests.get(full_status_check_url, headers=headers)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check Again! Using the same *task_id* "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "label,precision,recall,f1-score,support\n",
      "0,1.0,0.3,0.4615384615384615,10.0\n",
      "1,0.14285714285714285,0.2,0.16666666666666666,10.0\n",
      "2,0.2222222222222222,0.2,0.2105263157894737,10.0\n",
      "3,0.2857142857142857,0.4,0.3333333333333333,10.0\n",
      "accuracy,0.275,0.275,0.275,0.275\n",
      "macro avg,0.4126984126984127,0.275,0.2930161943319838,40.0\n",
      "weighted avg,0.41269841269841273,0.275,0.2930161943319837,40.0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "response = requests.get(full_status_check_url, headers=headers)\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
